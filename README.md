# Proyecto TÃ³picos avanzados en IA - Grupo 4

**Integrantes**

- **Julio CÃ©sar Roa DÃ¡vila**  
  <jcesarroa@javeriana.edu.co>

- **Jair SebastiÃ¡n Saavedra Alvarado**  
  <saavedra.jairs@javeriana.edu.co>

##  IntroducciÃ³n 

Debido a que los estudiantes, especialmente los nuevos, carecen del conocimiento sobre el contenido de este reglamento, resulta indispensable su difusiÃ³n desde el inicio de la vida acadÃ©mica. Este documento contiene informaciÃ³n clave sobre los derechos y deberes estudiantiles, los lineamientos a seguir en caso de conflicto e incluso aspectos importantes que los estudiantes podrÃ­an desconocer sobre sus propios derechos y deberes.

Con frecuencia, la divulgaciÃ³n del contenido del reglamento entre estudiantes puede ocurrir en forma similar a un "telÃ©fono roto", generando malinterpretaciones. AdemÃ¡s, algunos estudiantes consideran innecesaria su lectura para situaciones puntuales en su vida universitaria. Por tanto, nuestra soluciÃ³n proporciona un mecanismo amigable que permite a los estudiantes, sin importar en quÃ© etapa de su ciclo de vida acadÃ©mico se encuentren, acceder a esta informaciÃ³n de manera Ã¡gil y oportuna. Se trata de un asistente que ofrece informaciÃ³n directa y precisa del reglamento desde su base de conocimiento, facilitando asÃ­ un acceso mÃ¡s eficiente a los derechos y deberes para todos los estudiantes.

##  Objetivo 

Desarrollar, para la culminaciÃ³n del curso, un agente conversacional basado en la tÃ©cnica RAG utilizando embeddings del [reglamento estudiantil](https://www.javeriana.edu.co/institucional/reglamento-de-estudiantes "Reglamento"), empleando herramientas accesibles (versiÃ³n gratuita de GCP para aprendizaje), que permita responder de manera efectiva a preguntas con errores ortogrÃ¡ficos y que sea capaz de limitar su alcance al contenido de su base de conocimiento (reglamento estudiantil), advirtiendo al estudiante sobre estos lÃ­mites. De forma cuantitativa, se realizarÃ¡ una prueba de concepto con pares (estudiantes del curso) mediante una breve encuesta de aceptaciÃ³n tecnolÃ³gica [reglamento estudiantil](https://www.javeriana.edu.co/institucional/reglamento-de-estudiantes "Reglamento"), con lo cual se obtendrÃ¡ la retroalimentaciÃ³n necesaria sobre la versiÃ³n 1 antes de considerar su puesta en producciÃ³n como proyecto tecnolÃ³gico.

**Nota:** Debido a las caracterÃ­sticas del desarrollo, se compartirÃ¡ con los compaÃ±eros del curso el repositorio y el enlace a la encuesta, para que puedan proporcionarnos su retroalimentaciÃ³n.

Desgloce SMART:

- Specific (EspecÃ­fico): Desarrollar una prueba de concepto de un agente de inducciÃ³n - acompaÃ±amiento para estudiantes de la Pontifica Universidad Javeriana cuya base de conocimiento sea el reglamento estudiantil.

- Measurable (Medible): Optaremos por retroalimentaciÃ³n de pares, donde buscaremos retroalimentaciÃ³n por medio de una breve encuesta de aceptaciÃ³n tecnologica (TAM).

- Achivable (Alcanzable): Capa gratuita de GCP para estudio.

- Relevant (Relevante): Este proyecto sugiere un camino para permitir a los estudiantes a conocer de manera mÃ¡s fÃ¡cil y sencilla el contenido del reglamento estudiantil 

- Time-bound (Tiempo): Se dispone del cronograma de esta manera:

| Semana | Actividades                                                                                                                                                                                                                                     | Entregable Esperado                                                        |
| ------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------- |
| 1      | - DefiniciÃ³n y documentaciÃ³n del alcance del proyecto.<br>- RecopilaciÃ³n y preprocesamiento del reglamento estudiantil.<br>- Estudio inicial sobre RAG, embeddings y entorno GCP gratuito.<br>- DiseÃ±o de estrategia de embeddings.             | Documento de Alcance, Especificaciones y Estrategia de Embeddings definida |
| 2      | - CreaciÃ³n y validaciÃ³n tÃ©cnica de embeddings.<br>- ConfiguraciÃ³n del entorno gratuito GCP.<br>- ImplementaciÃ³n inicial del agente conversacional (RAG).<br>- Desarrollo de conexiÃ³n bÃ¡sica entre agente y embeddings.                          | Embeddings almacenados y prototipo bÃ¡sico funcional del agente             |
| 3      | - Refinamiento del agente RAG segÃºn pruebas internas.<br>- Desarrollo de interfaz amigable para consultas (e.g., Streamlit o Google Colab).<br>- Pruebas internas finales y validaciÃ³n tÃ©cnica.<br>- DocumentaciÃ³n tÃ©cnica final del prototipo. | Prototipo validado con interfaz y documentaciÃ³n tÃ©cnica final              |

## VisiÃ³n general y arquitectura del asistente de consultas del Reglamento Estudiantil PUJ

Este proyecto implementa un **asistente de inteligencia artificial** cuyo propÃ³sito es facilitar a los estudiantes de la **Pontificia Universidad Javeriana** la consulta Ã¡gil y precisa del **Reglamento Estudiantil**. 

La soluciÃ³n se diseÃ±Ã³ y desplegÃ³ **Ã­ntegramente en Google Cloud Platform (GCP)**, aprovechando los servicios incluidos en la capa gratuita. Para habilitar respuestas contextuales, se construyÃ³ una **base de conocimiento** donde **cada pÃ¡gina del reglamento** se trata como un documento independiente. Esa granularidad permite aplicar la tÃ©cnica de **Retrieval-Augmented Generation (RAG)**, garantizando que el asistente recupere los fragmentos relevantes del reglamento y genere respuestas fundamentadas en el texto oficial. Adicionalmente, para el desarrollo del proyecto se utilizo la siguiente arquitectura:


<div align="center">
  <img src="images/arquitectura_poc.png" alt="streamlit" width="1000"/>
</div>


| # | Componente | DescripciÃ³n |
|---|------------|-------------|
| 1 | **GeneraciÃ³n de embeddings** | 1. El PDF del Reglamento se **divide por pÃ¡ginas** y cada pÃ¡gina se transforma a imagen.<br>2. Sobre cada imagen se ejecuta **Gemini 2.5 Flash (multimodal)** para extraer el texto.<br>3. El texto se normaliza y se genera la representaciÃ³n vectorial con el modelo **`text-multilingual-embedding-002`** de Vertex AI (768 dimensiones).<br>4. Todo el proceso se orquesta desde un **Notebook** alojado en la misma VM y al final se produce un archivo `embedding_manual.json`. |
| 2 | **Base de conocimiento (OpenSearch)** | - Se despliega **OpenSearch** en un contenedor dentro de la mÃ¡quina virtual.<br>- Se crea el Ã­ndice `topicosindex` con dimensiÃ³n **768**.<br>- El archivo `embedding_manual.json` se carga en **OpenSearch**, quedando cada pÃ¡gina del reglamento como un documento con su vector. |
| 3 | **Asistente (LangChain + LangGraph + FastAPI)** | - Implementado con **LangGraph**: dos nodos.<br>  â€¢ `search_node` â†’ recupera los `5` documentos mÃ¡s relevantes desde OpenSearch.<br>  â€¢ `generate_node` â†’ construye el system prompt y llama a **Gemini 2.5 Pro** para redactar la respuesta.<br>- El grafo se expone a travÃ©s de un **backend FastAPI** (endpoint `POST /ask`).<br>- Todos los servicios (FastAPI, OpenSearch y Dashboards) se **orquestan mediante `docker-compose.yaml`**, facilitando la puesta en marcha con un solo comando. |
| 4 | **Frontend (Streamlit + ngrok)** | - Streamlit expone una interfaz chat que:<br>  â€¢ Mantiene el historial de la conversaciÃ³n.<br>  â€¢ Permite reiniciar sesiÃ³n.<br>- Para compartir la app pÃºblicamente sin exponer puertos se usa **ngrok**. |
| 5 | **Observabilidad (Langfuse)** | - **Langfuse** registra cada conversaciÃ³n de principio a fin bajo un mismo **ID de sesiÃ³n**, de forma que todas las preguntas y respuestas quedan agrupadas.<br>- En su panel se pueden ver mÃ©tricas como tiempo de respuesta, uso de tokens y los pasos internos que siguiÃ³ el asistente. |

> **Nota** los modelos **Gemini 2.5 Flash** y **Gemini 2.5 Pro** se encuentran en preview.


## Estructura del repositorio y guÃ­a de ejecuciÃ³n

El cÃ³digo se gestiona en **GitHub**, garantizando buenas prÃ¡cticas de control de versiones y colaboraciÃ³n. A continuaciÃ³n se detalla la estructura del repositorio:


### ğŸ“‚ Estructura del repositorio
```
TOPICOS_AVANZADOS/
â”œâ”€â”€ agent/                  # LÃ³gica del asistente y del grafo LangGraph
â”‚ â”œâ”€â”€ ai_graph_state.py     # DefiniciÃ³n del estado que circula por el grafo
â”‚ â”œâ”€â”€ graph.py              # ConstrucciÃ³n del grafo (nodos y conexiones)
â”‚ â”œâ”€â”€ invoker.py            # Clase que invoca el grafo y gestiona Langfuse
â”‚ â””â”€â”€ nodes.py              # ImplementaciÃ³n de los nodos (search / generate)
â”‚
â”œâ”€â”€ app/                    # Backend FastAPI + Dockerfile
â”‚ â”œâ”€â”€ Dockerfile            # Imagen para FastAPI + dependencias
â”‚ â”œâ”€â”€ main.py               # Endpoints (POST /ask)
â”‚ â””â”€â”€ requirements.txt      # LibrerÃ­as Python para FastAPI
â”‚
â”œâ”€â”€ embeddings/             # Insumos y notebook para generar embeddings
â”‚ â”œâ”€â”€ Proceso_embeddings.ipynb
â”‚ â”œâ”€â”€ reglamento-de-estudiantes-universidad-javeriana.pdf
â”‚ â””â”€â”€ imagenes/             # PÃ¡ginas del PDF
â”‚
â”œâ”€â”€ images/                 # Recursos grÃ¡ficos (diagramas, etc.)
â”‚
â”œâ”€â”€ prompts/                # Prompts del sistema en texto plano
â”‚ â””â”€â”€ prompt_generate.txt
â”‚
â”œâ”€â”€ utils/
â”‚ â””â”€â”€ chat_utils.py         # Clase VertexAILLM, OpenSearchSearcher, etc.
â”‚
â”œâ”€â”€ app.py                  # Frontend Streamlit
â”œâ”€â”€ docker-compose.yaml     # OrquestaciÃ³n (FastAPI + OpenSearch + Dashboards)
â”œâ”€â”€ embedding_manual.json   # Ejemplo de carga masiva en formato bulk
â””â”€â”€ README.md
```

A continuaciÃ³n se detallan los requisitos previos y los pasos necesarios para desplegar el asistente en un entorno local o de laboratorio.

| Requisito / Herramienta | Detalle o versiÃ³n mÃ­nima recomendada |
|-------------------------|--------------------------------------|
| **Cuenta de Google Cloud** | Proyecto activo con acceso a **Vertex AI** (modelos Gemini 2.5 Pro/Flash, Vector Search y modelo de embeddings). |
| **Cuenta de Langfuse**  | Espacio de trabajo (public / secret keys) para registrar las trazas de la aplicaciÃ³n. |
| **Docker**             | 24.x |
| **Docker Compose**     | 1.29.x |
| **Python** *(opcional)* | 3.10 + <br><sub>Solo necesario si se ejecutarÃ¡n los notebooks o Streamlit fuera de contenedor.</sub> |

Una vez cubiertos estos prerrequisitos, puede procederse al despliegue del asistente virtual.


1. Antes de iniciar OpenSearch es necesario ampliar el lÃ­mite de memoria:

```bash
sudo sysctl -w vm.max_map_count=262144
```

2. Desde la raÃ­z del repositorio, se debe ejecutar el siguiente comando para **construir e iniciar** todos los servicios (OpenSearch, Dashboards y FastAPI) mediante Docker Compose:

```bash
docker-compose up --build -d
```

Una vez finalizado, los servicios estarÃ¡n disponibles en:

- **OpenSearch**: https://localhost:9200  
- **OpenSearch Dashboards**: http://localhost:5601  
- **FastAPI (asistente)**: http://localhost:8000/docs



3. Con OpenSearch en ejecuciÃ³n, se crea el Ã­ndice **`topicosindex`** ejecutando:

```bash
curl -X PUT "https://localhost:9200/topicosindex" \
  -k \
  -u admin:Nagato123! \
  -H 'Content-Type: application/json' \
  -d '{
    "settings": {
      "index": {
        "knn": true,
        "number_of_shards": 1,
        "number_of_replicas": 0
      }
    },
    "mappings": {
      "properties": {
        "embedding": {
          "type": "knn_vector",
          "dimension": 768
        },
        "metadata": {
          "type": "object",
          "properties": {
            "filename": {
              "type": "keyword"
            },
            "tags": {
              "type": "keyword"
            },
            "id_documento": {
              "type": "integer"
            },
            "keyword": {
              "type": "keyword"
            },
            "title": {
              "type": "text",
              "fields": {
                "keyword": {
                  "type": "keyword",
                  "ignore_above": 256
                }
              }
            }
          }
        },
        "text": {
          "type": "text"
        }
      }
    }
  }'
```


4. Una vez generado el archivo `embedding_manual.json`, se puede importar directamente en el Ã­ndice `topicosindex` usando la API Bulk de OpenSearch:

```bash
curl -X POST "https://localhost:9200/topicosindex/_bulk" \
  -u admin:Nagato123! \
  -H "Content-Type: application/json" \
  --data-binary @embedding_manual.json \
  -k
```

> **Nota:** Para actualizar o modificar la base de conocimiento, basta con ejecutar nuevamente el notebook `embeddings/Proceso_embeddings.ipynb` y repetir los pasos de generaciÃ³n y carga de embeddings.


5. Para lanzar la aplicaciÃ³n de Streamlit y comenzar a interactuar con el asistente, ejecute:

```bash
streamlit run app.py
```

6. Para habilitar el acceso desde un dominio distinto a `localhost`, puede emplearse ngrok con el siguiente comando:

```bash
ngrok http --url=<domain> 8501
```

> **Nota:** Sustituir `<domain>` por el subdominio asignado a la cuenta de ngrok en uso.


## Consideraciones

El despliegue descrito corresponde a un **entorno de desarrollo de una PoC**. Antes de llevar la soluciÃ³n a producciÃ³n, se recomienda que usted tenga en cuenta los siguientes aspectos:

1. **Infraestructura limitada y no escalable**  
   Al ejecutarse en una Ãºnica instancia de Compute Engine, la arquitectura carece de alta disponibilidad y elasticidad. Ante picos de carga, el servicio podrÃ­a experimentar latencias elevadas o interrupciones.

2. **Cuenta de prueba de Google Cloud**  
   La PoC utiliza la capa gratuita de GCP. Para un entorno productivo se requiere una suscripciÃ³n que cubra los recursos consumidos y el acceso a servicios gestionados (Vertex AI, Cloud Logging, etc.).

3. **Modelos en modo *preview***  
   Gemini 2.5 Pro/Flash se emplean en modalidad *preview*, Ãºtil para experimentaciÃ³n, pero no recomendado en producciÃ³n debido a lÃ­mites de uso y ausencia de SLA. DeberÃ­a sustituirse por un modelo estable y con soporte.

4. **Cobertura de pruebas**  
   El prototipo no incluye pruebas unitarias, de integraciÃ³n ni de carga. Antes de la liberaciÃ³n se deben incorporar suites de pruebas alineadas con las polÃ­ticas de calidad de la organizaciÃ³n.

5. **PolÃ­ticas de seguridad y protecciÃ³n de datos**  
   Si la informaciÃ³n consultada es sensible, resulta obligatorio aplicar controles de seguridad (cifrado en reposo y en trÃ¡nsito, control de acceso, registro de auditorÃ­a, etc.) conforme a la normativa interna de la entidad.

6. **Observabilidad ampliada**  
   Langfuse ofrece trazabilidad a nivel del asistente; sin embargo, para operaciÃ³n continua se aconseja integrar mÃ©tricas de infraestructura (CPU, memoria, I/O) y alertas en un sistema de monitoreo centralizado (Cloud Monitoring, Prometheus, etc.).

Estas consideraciones deben evaluarse y ajustarse de acuerdo con los estÃ¡ndares de Gobierno de TI vigentes en su organizaciÃ³n.

## Propuesta de arquitectura productiva en Google Cloud Platform

Con el fin de llevar la soluciÃ³n a un entorno productivo, se recomienda la arquitectura del siguiente diagrama. Esta propuesta amplÃ­a la PoC y aÃ±ade robustez, escalabilidad y buenas prÃ¡cticas de gobernanza:

<div align="center">
  <img src="images/arquitectura_prod.png" alt="streamlit" width="1000"/>
</div>


1. **AutomatizaciÃ³n de embeddings y actualizaciÃ³n de la base vectorial**  
   - Los archivos fuente se cargan en **Cloud Storage**.  
   - Un mensaje de **Pub/Sub** actÃºa como disparador para **Cloud Run (Embeddings)**, servicio que:  
     1. Extrae el texto con **Gemini 2.5 Flash** (multimodal).  
     2. Genera embeddings mediante **`text-multilingual-embedding-002`**.  
     3. Actualiza la informaciÃ³n en **Vertex AI Vector Search**.  

2. **Consumo del asistente**  
   - La interfaz de usuario se implementa en **Apps Script**, facilitando la integraciÃ³n con entornos Google Workspace.  
   - Apps Script invoca un **Cloud Run (Backend)** que contiene la lÃ³gica del asistente (LangGraph + FastAPI).  
   - El backend consulta la base vectorial, genera la respuesta con **Gemini 2.5 Pro** y registra la traza en **Langfuse**.

3. **AnalÃ­tica y mejora continua**  
   - Las trazas almacenadas en Langfuse se exportan de forma periÃ³dica mediante un **Cloud Run (ELT)** hacia **BigQuery**.  
   - Los equipos de datos pueden explotar esta informaciÃ³n para obtener mÃ©tricas de uso, tiempos de respuesta y oportunidades de optimizaciÃ³n.

4. **Gobernanza y operaciones transversales**  
   - **GitHub** aloja el cÃ³digo fuente, permitiendo CI/CD y revisiÃ³n de cambios.  
   - Los artefactos de contenedor se publican en **Artifact Registry**.  
   - Los permisos de servicio y el acceso a los recursos se gestionan con **IAM**, garantizando principios de mÃ­nimo privilegio.

Esta arquitectura proporciona escalabilidad automÃ¡tica, alta disponibilidad y un flujo continuo de observabilidad y analÃ­tica, cumpliendo con los estÃ¡ndares empresariales para una puesta en producciÃ³n segura y mantenible.

> **Nota:** La arquitectura propuesta debe evaluarse y ajustarse por cada equipo que desee adoptarla, de modo que quede alineada con las polÃ­ticas internas de la organizaciÃ³n. Entre los puntos que suelen revisarse se incluyen:  
> 1. **Seguridad** â€“ definiciÃ³n de autenticaciÃ³n/ autorizaciÃ³n para las API y cifrado de datos en reposo y en trÃ¡nsito conforme a los requisitos corporativos.  
> 2. **Infraestructura como cÃ³digo (IaC)** â€“ uso de herramientas como Terraform para garantizar despliegues reproducibles y auditables.  
> 3. **Cuotas y alertamiento** â€“ establecimiento de lÃ­mites de consumo y notificaciones cuando se alcancen umbrales, especialmente si existe un presupuesto fijo asignado al proyecto o a los servicios en la nube.

## Demo