# Proyecto TÃ³picos avanzados en IA - Grupo 4

**Integrantes**

- **Julio CÃ©sar Roa DÃ¡vila**  
  <jcesarroa@javeriana.edu.co>

- **Jair SebastiÃ¡n Saavedra Alvarado**  
  <saavedra.jairs@javeriana.edu.co>

## VisiÃ³n general y arquitectura del asistente de consultas del Reglamento Estudiantil PUJ

Este proyecto implementa un **asistente de inteligencia artificial** cuyo propÃ³sito es facilitar a los estudiantes de la **Pontificia Universidad Javeriana** la consulta Ã¡gil y precisa del **Reglamento Estudiantil**.  

La soluciÃ³n se diseÃ±Ã³ y desplegÃ³ **Ã­ntegramente en Google Cloud Platform (GCP)**, aprovechando los servicios incluidos en la capa gratuita. Para habilitar respuestas contextuales, se construyÃ³ una **base de conocimiento** donde **cada pÃ¡gina del reglamento** se trata como un documento independiente. Esa granularidad permite aplicar la tÃ©cnica de **Retrieval-Augmented Generation (RAG)**, garantizando que el asistente recupere los fragmentos relevantes del reglamento y genere respuestas fundamentadas en el texto oficial. Adicionalmente, para el desarrollo del proyecto se utilizo la siguiente arquitectura:


<div align="center">
  <img src="images/arquitectura_poc.png" alt="streamlit" width="1000"/>
</div>


| # | Componente | DescripciÃ³n |
|---|------------|-------------|
| 1 | **GeneraciÃ³n de embeddings** | 1. El PDF del Reglamento se **divide por pÃ¡ginas** y cada pÃ¡gina se transforma a imagen.<br>2. Sobre cada imagen se ejecuta **Gemini 2.5 Flash (multimodal)** para extraer el texto con alta fidelidad.<br>3. El texto se normaliza y se genera la representaciÃ³n vectorial con el modelo **`text-multilingual-embedding-002`** de Vertex AI (768 dim).<br>4. Todo el proceso se orquesta desde un **Notebook** alojado en la misma VM y al final se produce un archivo `embedding_manual.json`. |
| 2 | **Base de conocimiento (OpenSearch)** | - Se despliega **OpenSearch** en un contenedor dentro de la VM.<br>- Se crea el Ã­ndice `topicosindex` con soporte **KNN** y dimensiÃ³n **768**.<br>- El archivo `embedding_manual.json` se carga vÃ­a API `_bulk`, quedando cada pÃ¡gina del reglamento como un documento con su vector. |
| 3 | **Asistente (LangChain + LangGraph + FastAPI)** | - Implementado con **LangGraph**: dos nodos.<br>  â€¢ `search_node` â†’ recupera los `k` documentos mÃ¡s relevantes desde OpenSearch.<br>  â€¢ `generate_node` â†’ construye el mensaje de sistema y llama a **Gemini 2.5 Pro** para redactar la respuesta.<br>- Se eligiÃ³ Gemini 2.5 Pro porque estÃ¡ en *preview* (sin coste) y ofrece mayor capacidad de razonamiento.<br>- El grafo se expone a travÃ©s de un **backend FastAPI** (endpoint `POST /ask`).<br>- Todo el stack (FastAPI, OpenSearch y Dashboards) se **orquesta mediante `docker-compose.yaml`**, facilitando la puesta en marcha con un solo comando. |
| 4 | **Frontend (Streamlit + ngrok)** | - Streamlit expone una interfaz chat que:<br>  â€¢ Mantiene el historial de la conversaciÃ³n.<br>  â€¢ Permite reiniciar sesiÃ³n.<br>- Para compartir la app pÃºblicamente sin exponer puertos se usa **ngrok**, que crea un tÃºnel HTTPS temporal hacia la instancia de Streamlit. |
| 5 | **Observabilidad (Langfuse)** | - **Langfuse** registra cada conversaciÃ³n de principio a fin bajo un mismo **ID de sesiÃ³n**, de forma que todas las preguntas y respuestas quedan agrupadas.<br>- En su panel se pueden ver mÃ©tricas como tiempo de respuesta, uso de tokens y los pasos internos que siguiÃ³ el asistente, lo que facilita el seguimiento y la mejora continua. |

> **Todo el stack corre en una Ãºnica VM de Compute Engine** (entorno de desarrollo/experimentaciÃ³n) aprovechando la capa gratuita de Google Cloud Platform.


## Estructura del repositorio y guÃ­a de ejecuciÃ³n

El cÃ³digo se gestiona en **GitHub**, garantizando buenas prÃ¡cticas de control de versiones y colaboraciÃ³n. A continuaciÃ³n se detalla la estructura del repositorio:


### ðŸ“‚ Estructura del repositorio
```
TOPICOS_AVANZADOS/
â”œâ”€â”€ agent/                  # LÃ³gica del asistente y del grafo LangGraph
â”‚ â”œâ”€â”€ ai_graph_state.py     # DefiniciÃ³n del estado que circula por el grafo
â”‚ â”œâ”€â”€ graph.py              # ConstrucciÃ³n del grafo (nodos y conexiones)
â”‚ â”œâ”€â”€ invoker.py            # Clase que invoca el grafo y gestiona Langfuse
â”‚ â””â”€â”€ nodes.py              # ImplementaciÃ³n de los nodos (search / generate)
â”‚
â”œâ”€â”€ app/ # Backend FastAPI + Dockerfile
â”‚ â”œâ”€â”€ Dockerfile            # Imagen para FastAPI + dependencias
â”‚ â”œâ”€â”€ main.py               # Endpoints (POST /ask)
â”‚ â””â”€â”€ requirements.txt      # LibrerÃ­as Python para FastAPI
â”‚
â”œâ”€â”€ embeddings/             # Insumos y notebook para generar embeddings
â”‚ â”œâ”€â”€ Proceso_embeddings.ipynb
â”‚ â”œâ”€â”€ reglamento-de-estudiantes-universidad-javeriana.pdf
â”‚ â””â”€â”€ imagenes/             # PÃ¡ginas del PDF rasterizadas
â”‚
â”œâ”€â”€ images/                 # Recursos grÃ¡ficos (diagramas, etc.)
â”‚
â”œâ”€â”€ prompts/                # Prompts del sistema en texto plano
â”‚ â””â”€â”€ prompt_generate.txt
â”‚
â”œâ”€â”€ utils/
â”‚ â””â”€â”€ chat_utils.py         # Clase VertexAILLM, OpenSearchSearcher, etc.
â”‚
â”œâ”€â”€ app.py                  # Frontend Streamlit
â”œâ”€â”€ docker-compose.yaml     # OrquestaciÃ³n (FastAPI + OpenSearch + Dashboards)
â”œâ”€â”€ embedding_manual.json   # Ejemplo de carga masiva en formato bulk
â””â”€â”€ README.md
```

A continuaciÃ³n se detallan los requisitos previos y los pasos necesarios para desplegar el asistente en un entorno local o de laboratorio.

| Requisito / Herramienta | Detalle o versiÃ³n mÃ­nima recomendada |
|-------------------------|--------------------------------------|
| **Cuenta de Google Cloud** | Proyecto activo con acceso a **Vertex AI** (modelos Gemini 2.5 Pro/Flash y Vector Search). |
| **Cuenta de Langfuse**  | Espacio de trabajo (public / secret keys) para registrar las trazas de la aplicaciÃ³n. |
| **Docker**             | 24.x |
| **Docker Compose**     | 1.29.x |
| **Python** *(opcional)* | 3.10 + <br><sub>Solo necesario si se ejecutarÃ¡n los notebooks o Streamlit fuera de contenedor.</sub> |

Una vez cubiertos estos prerrequisitos, puede procederse al despliegue del asistente virtual.


1. Antes de iniciar OpenSearch es necesario ampliar el lÃ­mite de memoria de mapeo:

```bash
sudo sysctl -w vm.max_map_count=262144
```

2. Desde la raÃ­z del repositorio, ejecute el siguiente comando para **construir e iniciar** todos los servicios (OpenSearch, Dashboards y FastAPI) mediante Docker Compose:

```bash
docker-compose up --build -d
```

Una vez finalizado, los servicios estarÃ¡n disponibles en:

- **OpenSearch**: https://localhost:9200  
- **OpenSearch Dashboards**: http://localhost:5601  
- **FastAPI (asistente)**: http://localhost:8000/docs



3. Con OpenSearch en ejecuciÃ³n, cree el Ã­ndice **`topicosindex`** con soporte para bÃºsqueda vectorial (KNN) ejecutando:

```bash
curl -X PUT "https://localhost:9200/topicosindex" \
  -k \
  -u admin:Nagato123! \
  -H 'Content-Type: application/json' \
  -d '{
    "settings": {
      "index": {
        "knn": true,
        "number_of_shards": 1,
        "number_of_replicas": 0
      }
    },
    "mappings": {
      "properties": {
        "embedding": {
          "type": "knn_vector",
          "dimension": 768
        },
        "metadata": {
          "type": "object",
          "properties": {
            "filename": {
              "type": "keyword"
            },
            "tags": {
              "type": "keyword"
            },
            "id_documento": {
              "type": "integer"
            },
            "keyword": {
              "type": "keyword"
            },
            "title": {
              "type": "text",
              "fields": {
                "keyword": {
                  "type": "keyword",
                  "ignore_above": 256
                }
              }
            }
          }
        },
        "text": {
          "type": "text"
        }
      }
    }
  }'
```


4. Una vez generado el archivo `embedding_manual.json`, se puede importar directamente en el Ã­ndice `topicosindex` usando la API Bulk de OpenSearch:

```bash
curl -X POST "https://localhost:9200/topicosindex/_bulk" \
  -u admin:Nagato123! \
  -H "Content-Type: application/json" \
  --data-binary @embedding_manual.json \
  -k
```

> **Nota:** Para actualizar o modificar la base de conocimiento, basta con ejecutar nuevamente el notebook `embeddings/Proceso_embeddings.ipynb` y repetir los pasos de generaciÃ³n y carga de embeddings.


5. Para lanzar la aplicaciÃ³n de Streamlit y comenzar a interactuar con el asistente, ejecute:

```bash
streamlit run app.py
```

6. Para habilitar el acceso desde un dominio distinto a `localhost`, puede emplearse ngrok con el siguiente comando:

```bash
ngrok http --url=<domain> 8501
```

> **Nota:** Sustituir `<domain>` por el subdominio asignado a la cuenta de ngrok en uso.


## Consideraciones

El despliegue descrito corresponde a un **entorno de desarrollo (Proof of Concept)**. Antes de llevar la soluciÃ³n a producciÃ³n, se recomienda que usted tenga en cuenta los siguientes aspectos:

1. **Infraestructura limitada y no escalable**  
   Al ejecutarse en una Ãºnica instancia de Compute Engine, la arquitectura carece de alta disponibilidad y elasticidad. Ante picos de carga, el servicio podrÃ­a experimentar latencias elevadas o interrupciones.

2. **Cuenta de prueba de Google Cloud**  
   La PoC utiliza la capa gratuita de GCP. Para un entorno productivo se requiere una suscripciÃ³n que cubra los recursos consumidos y el acceso a servicios gestionados (Vertex AI, Cloud Logging, etc.).

3. **Modelos en modo *preview***  
   Gemini 2.5 Pro se emplea en modalidad *preview* â€” Ãºtil para experimentaciÃ³n, pero no recomendado en producciÃ³n debido a lÃ­mites de uso y ausencia de SLA. DeberÃ­a sustituirse por un modelo estable y con soporte.

4. **Cobertura de pruebas**  
   El prototipo no incluye pruebas unitarias, de integraciÃ³n ni de carga. Antes de la liberaciÃ³n se deben incorporar suites de pruebas alineadas con las polÃ­ticas de calidad de la organizaciÃ³n.

5. **PolÃ­ticas de seguridad y protecciÃ³n de datos**  
   Si la informaciÃ³n consultada es sensible, resulta obligatorio aplicar controles de seguridad (cifrado en reposo y en trÃ¡nsito, control de acceso, registro de auditorÃ­a, etc.) conforme a la normativa interna de la entidad.

6. **Observabilidad ampliada**  
   Langfuse ofrece trazabilidad a nivel de aplicaciÃ³n; sin embargo, para operaciÃ³n continua se aconseja integrar mÃ©tricas de infraestructura (CPU, memoria, I/O) y alertas en un sistema de monitoreo centralizado (Cloud Monitoring, Prometheus, etc.).

Estas consideraciones deben evaluarse y ajustarse de acuerdo con los estÃ¡ndares de Gobierno de TI vigentes en su organizaciÃ³n.

## Propuesta de arquitectura productiva en Google Cloud Platform

Con el fin de llevar la soluciÃ³n a un entorno productivo, se recomienda la arquitectura ilustrada en el diagrama precedente. Esta propuesta amplÃ­a la PoC y aÃ±ade robustez, escalabilidad y buenas prÃ¡cticas de gobernanza:

<div align="center">
  <img src="images/arquitectura_prod.png" alt="streamlit" width="1000"/>
</div>


1. **AutomatizaciÃ³n de embeddings y actualizaciÃ³n de la base vectorial**  
   - Los archivos fuente se cargan en **Cloud Storage**.  
   - Un mensaje de **Pub/Sub** actÃºa como disparador para **Cloud Run (Embeddings)**, servicio que:  
     1. Extrae el texto con **Gemini 2.5 Flash** (multimodal).  
     2. Genera embeddings mediante **`text-multilingual-embedding-002`**.  
     3. Actualiza la colecciÃ³n en **Vertex AI Vector Search**.  

2. **Consumo del asistente**  
   - La interfaz de usuario se implementa en **Apps Script**, facilitando la integraciÃ³n con entornos Google Workspace.  
   - Apps Script invoca un **Cloud Run (Backend)** que contiene la lÃ³gica del asistente (LangGraph + FastAPI).  
   - El backend consulta la base vectorial, genera la respuesta con **Gemini 2.5 Pro** y registra la traza en **Langfuse**.

3. **AnalÃ­tica y mejora continua**  
   - Las trazas almacenadas en Langfuse se exportan de forma periÃ³dica mediante un **Cloud Run (ELT)** hacia **BigQuery**.  
   - Los equipos de datos pueden explotar esta informaciÃ³n para obtener mÃ©tricas de uso, tiempos de respuesta y oportunidades de optimizaciÃ³n.

4. **Gobernanza y operaciones transversales**  
   - **GitHub** aloja el cÃ³digo fuente, permitiendo CI/CD y revisiÃ³n de cambios.  
   - Los artefactos de contenedor se publican en **Artifact Registry**.  
   - Los permisos de servicio y el acceso a los recursos se gestionan con **IAM**, garantizando principios de mÃ­nimo privilegio.

Esta arquitectura proporciona escalabilidad automÃ¡tica, alta disponibilidad y un flujo continuo de observabilidad y analÃ­tica, cumpliendo con los estÃ¡ndares empresariales para una puesta en producciÃ³n segura y mantenible.

> **Nota:** La arquitectura propuesta debe evaluarse y ajustarse por cada equipo que desee adoptarla, de modo que quede alineada con las polÃ­ticas internas de la organizaciÃ³n. Entre los puntos que suelen revisarse se incluyen:  
> 1. **Seguridad** â€“ definiciÃ³n de autenticaciÃ³n/ autorizaciÃ³n para las API y cifrado de datos en reposo y en trÃ¡nsito conforme a los requisitos corporativos.  
> 2. **Infraestructura como cÃ³digo (IaC)** â€“ uso de herramientas como Terraform para garantizar despliegues reproducibles y auditables.  
> 3. **Cuotas y alertamiento** â€“ establecimiento de lÃ­mites de consumo y notificaciones cuando se alcancen umbrales, especialmente si existe un presupuesto fijo asignado al proyecto o a los servicios en la nube.
